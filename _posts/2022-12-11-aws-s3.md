---
layout: post
title: "AWS - S3"
description: ""
category: posts
tags: [aws, s3, aws-dev-ops-pro, aws-solutions-arch-pro]
---
{% include JB/setup %}

# Amazon Simple Storage Service
S3 is an object based storage and is a key-value based - the key is the file name; the value is the data in the file plus some other data like the Version ID, access control information and metadata. S3 offers *Read after Write* consistency for `PUT` and `DELETE` and **only** *Eventual* consistency for update for `UPDATE`.

The minimium size for a s3 object is 0 bytes; 100 S3 buckets per account; 5Tb object size max. AWS charges you for storage, requests, and data transfer. Bucket names can not start with a '.' or '-' and cannot be formatted like an IP address. 

## S3 Storage Classes

- S3 - AWS guarantees 99.99% availability for the S3 Platform and 11 x 9 for durability.

- S3-Infrequently Accessed - Less frequently used data that needs rapid access - there is a charge for retrieval; 99.9% availability; minimum charge of 30 days and 128kb regardless of size.

- S3-One Zone-IA (used to be called Reduced Redundancy Storage) - 99.99% durability & availablity - like the name suggests files are only stored in a single region. Useful for files that can be regen'd like thumbnails. 128kb minimium size

- [S3 Glacier Instant ](https://aws.amazon.com/glacier/) - an object storage capability that is mostly offline and way, way cheaper than S3 Standard. It's like S3-IA but minimiun charge is for 90 days, the storage cost is less expensive but retrieval cost is higher. 128kb minimium size

- S3 Glacier Flexible - this was formally known as S3 Glacier - objects appear in a bucket but you must retrieve them to a S3-IA using _expedited_ (1-5 minutes), _standard_ (3-5 hours), or _bulk_ (5-12 hours). Also has a 90 day minimium and 40kb minimium size.

- S3 Deep archive - think frozen data; retrieval is really slow - _standard_ 12 hours and _bulk_ which is up to 48 hours. Also has a 180 day minimium and 40kb minimium size.

- S3 Intelligent tiering - uses AI to put the data in the right storage class; slightly modified storage classes with Archive Access and Deep Archive as options

## Storage Classes & Lifecycle Rules

S3 lifecycle Rules - These are XML documents that are stored as a lifecycle sub-resource attached to the bucket. `PUT`, `GET` and `DELETE` actions can be done with the lifecycle policies. Transitions between classes have minimium times.. sometimes.

- S3 -> S3-IA - must be here for a minimum of 30 days (and be 128kb) before it can move to glacier

- S3 -> Glacier - can move here directly after creation if needed

- S3 -> Permenantly Delete - yep, cool stuff this.

- Can't move from SA-IA -> RRS or S3

- Move to Glacier? if 128k (directlyAfterCreation == true || daysInS3-IA > 30 days) 

- Move from Glacier? nope.

## Access Control

Buckets are private by default; access control is executed using an IAM policy, a bucket policy, or an access control list (ACL). ACLs are not recommended. Access logs and CloudTrail are useful for audit and traceability.

### IAM Policies for S3

S3 IAM policies can NOT grant anonymous access; use pre-signed URLs for this use case. But you can DENY access with IAM Policies. The star (*) can be used in a policy as a wild card as can template strings like: `${aws:username}`

### Bucket Policies

While IAM policies apply to the user level, bucket policies apply to the resource level. Bucket owners can specify what other users can do the contents of the bucket. Use Bucket Policies to grant public access, force encryption, cross account access; conditions include: 
0. Public or Elastic IP (but not Private IP) for Source IP, 
0. Source VPC or Source VPC Endpoint
0. CloudFront Origin
0. MFA

### S3 Bucket ACL

Stored in XML and can be used to manage access to objects NOT owned by the bucket owner. They can not explicitly deny permissions; they grant read and write permissions to other AWS accounts. Bucket ACLs are not recommended.

### Cross account access
Three ways to make this happen:
1. bucket policy and IAM - entire bucket, programmatic access only.

1. Cross account IAM role - programmatic and console access 

### Pre-signed URLs
Recipient of URL has same rights as principle that signed; can use SDK/CLI for downloads; must use SDK for uploads. 3600 seconds timeout that can be changed using the `expires-in [seconds]` option

## Data Security

Data in-transit security happens using SSL or TLS. To enfore HTTPS, use the `aws:SecureTransport` condition. MFA delete is an option that keeps randos from deleting your stuff. Customer can also encrypted on the client side. All Glacier data is AES-256 encrypted using AWS keys.

Data at-Rest - There are three flavors of Server Side Encryption (SSE) Server side encryption can be enabled using the REST API using x-amz-server-side-encryption header.

* SSE-S3 - keys handled and managed by AWS

* SSE-KMS - KMS Managed Keys; provides an audit trail using CloudTrail, the `kms:GenerateDataKey` permission must be present when writing to S3 (s3:PutObject). KMS decryption has a hard limit for the number of requests possible and the number is region specific; could be 5,500, 10K or 30K per second.

* Customer Provided Keys (SSE-C) - you provide key; you manage key; you upload key to AWS...

### S3 Endpoints
S3 exposes an HTTP and HTTPS public endpoint; HTTPS is mandatory for SSE-C.

#### S3 Gateway Endpoints
To secure S3 further, enable an S3 Gateway endpoint for private subnets. Use the bucket policy to restrict access on `AWS:SourceVpce` or `AWS:SourceVpc`

End points can't be used for NACL but can be used for SG, can't be moved to another VPC, can't be extended outside of the VPC, and can't be tagged. This also requires DNS resolution in the VPC. End points can have policies which are more like bucket policies and require a `Principle` to be defined.

## S3 Access Points
Each Access Point gets it's own DNS and policy making it easier to admin that complex bucket policies. Policies can restrict traffice from a specific VPC; access points are linked to specific bucket.
Privately share bucket in other accounts scenario:
0. Create S3 Access point in account sharing bucket using "Condition" `S3:AccessPointNetworkOrigin: VPC` (Restrict traffic to outside the VPC)
0. Create Gateway Endpoint linking it to the S3 Access point in the shared bucket account
0. Create Gateway Endpoint Policy enabling access

## Versioning

Stores all version of an object and can be used with MFA to provide extra layer of DELETE security.  ALL version of the file are stored so the amount of spaced required can end up being HUGE. Versioning only starts after it is enable and files have been added - existing files end up with a NULL version. Specific versions of files can be made public; later versions of a public file are NOT public. Versioning can be suspended, which keeps all file versions created so far, but versioning can not be turned off for a bucket. When a versioned file is delete a delete flag is enabled.

## S3 Select, Glacier Select & Byte-range fetch
S3 select and Glacier select enables the retrieval of data using simple SQL statements and is similiar to Athena except for a single file. This enables you to download just the data you need from a CSV without downloading the entire file.

S3 also has a byte-range fetch which parallelizes downloads... this can be used for speeding the downloads of an entire file OR partial amounts of a file.

## S3 Website Hosting

The minimium steps to make a website on S3 is to create an index document to your S3 bucket, enable static website hosting in your S3 bucket properties, select the 'Make Public' permission for your bucketâ€™s objects or apply a bucket policy. The only allowed domain prefix when creating Route 53 Aliases for S3 static websites is the 'www' prefix but you can create Aliases that point to the www alias. S3 buckets do not have https.

CORS rules - The bucket hosting the assets needs CORS configuration - add the domain of the "static" site to fix this up.

## S3 Transfer Acceleration

Edge Location used by CloudFront are not just for download acceleration. S3 Transfer Acceleration uses the AWS backbone to speed up uploads. This costs more money. There is a distinct URL that syncs from the CloudFront edge locations to S3 bucket.

## Cross region replication

Cross region replication requires versioning (on both ends) and an IAM role setup. Once replication is turned on, only new/modified objects are replicated; delete markers are not replicated but public permissions are replicated between buckets.

## S3 Object Lock & Glacier Vault Lock
Object lock is available for S3 and Glacier enabling you to store objects in a write once, read many times model (WORM). There are two modes: governance mode and compliance mode. Governance mode is for when you want to protect data for a period of time but want admin control to be able to over-ride the protection. Compliance mode is protected until the retention date has passed.

Object lock has a retention period, from 1 to no max # of days, and a legal hold. The legal hold must be explicitly removed to change the file. 

## Multi Part Upload
Multi-part upload API allows you to upload parts of an object once broken apart. Multipart uploads are recommended for files >100Mb and required for files over 5 GB.

As a file/object is being created, the multi-part upload API will allow you to upload the file to S3. Only after all parts of the object have been uploaded do you execute the CompleteMultipartUpload API call which completes a multi-part upload by assembling previously uploaded parts.

You first initiate the multi-part upload and then upload all parts using the Upload Parts operation (see Upload Part). After successfully uploading all relevant parts of an upload, you call this operation to complete the upload. Upon receiving this request, Amazon S3 concatenates all the parts in ascending order by part number to create a new object. In the Complete Multi-part Upload request, you must provide the parts list. You must ensure the parts list is complete, this operation concatenates the parts you provide in the list. For each part in the list, you must provide the part number and the ETag header value, returned after that part was uploaded.

## S3 Storage Lens
S3 Storage Lens delivers _Organization_-wide, as in AWS Organizations, visibility into object storage usage, activity trends, and makes actionable recommendations to optimize costs and apply data protection best practices. 

Data can be aggregated across an organization, accounts, regions, and buckets into a default or customer dashbard; the data can also be exported daily to an S3 bucket in CSV or Parquet format. The default dashboard is free, can be disabled but not deleted. For more cash, advanced metrics and recommendations includes CloudWatch publishing, and prefix aggregation are available.

## S3 Performance
Using a sequential prefix, such as time-stamp or an alphabetical sequence, increases the likelihood that Amazon S3 will target a specific partition for a large number of your keys, overwhelming the I/O capacity of the partition. If you introduce some randomness in your key name prefixes the I/O load will be distributed across more than one partition. You can use this approach to get 3.5k PUT/COPY/POST/DELETE and 5.5 GET/HEAD requests per second per prefix.

## Access Logging and Events

- S3 Access logs - takes hours and might be incomplete
- s3 Event Notifications - seconds to minutes for delivery to SNS, SQS or Lambda; lots of notifications with versioning; it's possible to get just one notification for simultaneous writes
- Trusted Advisor - public bucket?
- EventBridge - enable CloudTrail object logging on S3 first
